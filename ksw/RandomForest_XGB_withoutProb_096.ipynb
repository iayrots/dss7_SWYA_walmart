{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depts_tmp = train_grouped.loc[:, \"1-HR PHOTO\":\"WIRELESS\"]\n",
    "depts_tmp = depts_smoothed\n",
    "depts_tmp.columns = depts_tmp.columns.map(lambda x: str(\"Prob_\") + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../dataset/0408_noFineline_train.csv\")\n",
    "test = pd.read_csv(\"../dataset/0408_noFineline_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VisitNumber</th>\n",
       "      <th>ScanCount</th>\n",
       "      <th>Count</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Range</th>\n",
       "      <th>Null_Depts</th>\n",
       "      <th>ReturnCount</th>\n",
       "      <th>Null_Fineline</th>\n",
       "      <th>...</th>\n",
       "      <th>Prob_TOYS</th>\n",
       "      <th>Prob_WIRELESS</th>\n",
       "      <th>FinelineNumber</th>\n",
       "      <th>Weekday_0</th>\n",
       "      <th>Weekday_1</th>\n",
       "      <th>Weekday_2</th>\n",
       "      <th>Weekday_3</th>\n",
       "      <th>Weekday_4</th>\n",
       "      <th>Weekday_5</th>\n",
       "      <th>Weekday_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>8931.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VisitNumber  ScanCount  Count  Min   Max      Mean  Range  Null_Depts  \\\n",
       "0            5         -1      0  0.0   0.0  0.000000    0.0         0.0   \n",
       "1            7          1      1  1.0   1.0  1.000000    0.0         0.0   \n",
       "2            8          3      3  1.0  20.0  4.833333   19.0         0.0   \n",
       "3            9          1      1  1.0   2.0  1.500000    1.0         0.0   \n",
       "4           10          1      1  1.0   2.0  1.500000    1.0         0.0   \n",
       "\n",
       "   ReturnCount  Null_Fineline    ...      Prob_TOYS  Prob_WIRELESS  \\\n",
       "0          0.0            0.0    ...       0.014706       0.014706   \n",
       "1          0.0            0.0    ...       0.014286       0.014286   \n",
       "2          0.0            0.0    ...       0.010204       0.010204   \n",
       "3          0.0            0.0    ...       0.014085       0.014085   \n",
       "4          0.0            0.0    ...       0.014085       0.014085   \n",
       "\n",
       "   FinelineNumber  Weekday_0  Weekday_1  Weekday_2  Weekday_3  Weekday_4  \\\n",
       "0          1000.0          0          0          0          0          1   \n",
       "1          8931.0          0          0          0          0          1   \n",
       "2          3565.0          0          0          0          0          1   \n",
       "3           115.0          0          0          0          0          1   \n",
       "4          2008.0          0          0          0          0          1   \n",
       "\n",
       "   Weekday_5  Weekday_6  \n",
       "0          0          0  \n",
       "1          0          0  \n",
       "2          0          0  \n",
       "3          0          0  \n",
       "4          0          0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_cols = []\n",
    "cols = train.columns.tolist()\n",
    "for col in cols:\n",
    "    if col.startswith(\"Prob_\"):\n",
    "        prob_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Prob_1-HR PHOTO', 'Prob_WIRELESS')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_cols[0], prob_cols[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wihouth_prob = train.drop(train.loc[:, prob_cols[0]:prob_cols[-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_with_prob = test.drop(test.loc[:, prob_cols[0]:prob_cols[-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_df = pd.read_csv(\"../dataset/0409_train.csv\").set_index(\"VisitNumber\")[\"TripType\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_array = train_wihouth_prob.values\n",
    "test_array = test_with_prob.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_array, y_df, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, min_samples_split=30, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=30,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.736394676329\n",
      "0.657468957732\n"
     ]
    }
   ],
   "source": [
    "print(rf.score(X_train, y_train))\n",
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_test = rf.predict_proba(test_array)\n",
    "proba_df = pd.DataFrame(pred_prob_test, columns=rf.classes_)\n",
    "proba_df.columns = proba_df.columns.map(lambda x: \"TripType_\" + str(x))\n",
    "sub_df = pd.concat([test[[\"VisitNumber\"]], proba_df], axis=1)\n",
    "sub_df.to_csv(\"../submission_0409_noProb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label = LabelEncoder().fit(y_df.values)\n",
    "y_labeled = label.transform(y_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_labeled_train, y_labeled_test = train_test_split(y_labeled, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_labeled_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_labeled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:3.00377\teval-mlogloss:3.00471\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain-mlogloss:2.50616\teval-mlogloss:2.50957\n",
      "[2]\ttrain-mlogloss:2.15493\teval-mlogloss:2.15923\n",
      "[3]\ttrain-mlogloss:1.94009\teval-mlogloss:1.9461\n",
      "[4]\ttrain-mlogloss:1.78965\teval-mlogloss:1.79686\n",
      "[5]\ttrain-mlogloss:1.67662\teval-mlogloss:1.68517\n",
      "[6]\ttrain-mlogloss:1.58791\teval-mlogloss:1.59692\n",
      "[7]\ttrain-mlogloss:1.51547\teval-mlogloss:1.52523\n",
      "[8]\ttrain-mlogloss:1.45498\teval-mlogloss:1.46558\n",
      "[9]\ttrain-mlogloss:1.40392\teval-mlogloss:1.41584\n",
      "[10]\ttrain-mlogloss:1.36247\teval-mlogloss:1.37522\n",
      "[11]\ttrain-mlogloss:1.32655\teval-mlogloss:1.33958\n",
      "[12]\ttrain-mlogloss:1.29391\teval-mlogloss:1.30771\n",
      "[13]\ttrain-mlogloss:1.2668\teval-mlogloss:1.28157\n",
      "[14]\ttrain-mlogloss:1.24353\teval-mlogloss:1.25926\n",
      "[15]\ttrain-mlogloss:1.2222\teval-mlogloss:1.23874\n",
      "[16]\ttrain-mlogloss:1.20299\teval-mlogloss:1.22037\n",
      "[17]\ttrain-mlogloss:1.18702\teval-mlogloss:1.20502\n",
      "[18]\ttrain-mlogloss:1.17256\teval-mlogloss:1.19129\n",
      "[19]\ttrain-mlogloss:1.15692\teval-mlogloss:1.17669\n",
      "[20]\ttrain-mlogloss:1.14461\teval-mlogloss:1.16531\n",
      "[21]\ttrain-mlogloss:1.13312\teval-mlogloss:1.1547\n",
      "[22]\ttrain-mlogloss:1.1228\teval-mlogloss:1.14529\n",
      "[23]\ttrain-mlogloss:1.11268\teval-mlogloss:1.13623\n",
      "[24]\ttrain-mlogloss:1.10276\teval-mlogloss:1.1272\n",
      "[25]\ttrain-mlogloss:1.09479\teval-mlogloss:1.12056\n",
      "[26]\ttrain-mlogloss:1.08681\teval-mlogloss:1.11338\n",
      "[27]\ttrain-mlogloss:1.07869\teval-mlogloss:1.10628\n",
      "[28]\ttrain-mlogloss:1.07178\teval-mlogloss:1.10051\n",
      "[29]\ttrain-mlogloss:1.06517\teval-mlogloss:1.0947\n",
      "[30]\ttrain-mlogloss:1.05956\teval-mlogloss:1.08976\n",
      "[31]\ttrain-mlogloss:1.05321\teval-mlogloss:1.08477\n",
      "[32]\ttrain-mlogloss:1.0471\teval-mlogloss:1.07997\n",
      "[33]\ttrain-mlogloss:1.0411\teval-mlogloss:1.07532\n",
      "[34]\ttrain-mlogloss:1.03519\teval-mlogloss:1.07042\n",
      "[35]\ttrain-mlogloss:1.02959\teval-mlogloss:1.06574\n",
      "[36]\ttrain-mlogloss:1.02498\teval-mlogloss:1.06198\n",
      "[37]\ttrain-mlogloss:1.01942\teval-mlogloss:1.05755\n",
      "[38]\ttrain-mlogloss:1.01551\teval-mlogloss:1.05503\n",
      "[39]\ttrain-mlogloss:1.01138\teval-mlogloss:1.05195\n",
      "[40]\ttrain-mlogloss:1.00727\teval-mlogloss:1.04891\n",
      "[41]\ttrain-mlogloss:1.00348\teval-mlogloss:1.04624\n",
      "[42]\ttrain-mlogloss:0.997884\teval-mlogloss:1.0418\n",
      "[43]\ttrain-mlogloss:0.993546\teval-mlogloss:1.0385\n",
      "[44]\ttrain-mlogloss:0.990122\teval-mlogloss:1.03626\n",
      "[45]\ttrain-mlogloss:0.986451\teval-mlogloss:1.03353\n",
      "[46]\ttrain-mlogloss:0.983415\teval-mlogloss:1.03175\n",
      "[47]\ttrain-mlogloss:0.980201\teval-mlogloss:1.02964\n",
      "[48]\ttrain-mlogloss:0.976682\teval-mlogloss:1.02713\n",
      "[49]\ttrain-mlogloss:0.973367\teval-mlogloss:1.025\n",
      "[50]\ttrain-mlogloss:0.970244\teval-mlogloss:1.02328\n",
      "[51]\ttrain-mlogloss:0.966992\teval-mlogloss:1.02094\n",
      "[52]\ttrain-mlogloss:0.963622\teval-mlogloss:1.01854\n",
      "[53]\ttrain-mlogloss:0.960711\teval-mlogloss:1.01659\n",
      "[54]\ttrain-mlogloss:0.958209\teval-mlogloss:1.015\n",
      "[55]\ttrain-mlogloss:0.955025\teval-mlogloss:1.0128\n",
      "[56]\ttrain-mlogloss:0.952081\teval-mlogloss:1.01109\n",
      "[57]\ttrain-mlogloss:0.949506\teval-mlogloss:1.00961\n",
      "[58]\ttrain-mlogloss:0.947009\teval-mlogloss:1.0082\n",
      "[59]\ttrain-mlogloss:0.944238\teval-mlogloss:1.00655\n",
      "[60]\ttrain-mlogloss:0.941303\teval-mlogloss:1.00465\n",
      "[61]\ttrain-mlogloss:0.938304\teval-mlogloss:1.00287\n",
      "[62]\ttrain-mlogloss:0.936004\teval-mlogloss:1.00151\n",
      "[63]\ttrain-mlogloss:0.933225\teval-mlogloss:0.999916\n",
      "[64]\ttrain-mlogloss:0.931359\teval-mlogloss:0.998978\n",
      "[65]\ttrain-mlogloss:0.929242\teval-mlogloss:0.997991\n",
      "[66]\ttrain-mlogloss:0.927019\teval-mlogloss:0.996524\n",
      "[67]\ttrain-mlogloss:0.924868\teval-mlogloss:0.995367\n",
      "[68]\ttrain-mlogloss:0.922938\teval-mlogloss:0.99455\n",
      "[69]\ttrain-mlogloss:0.920915\teval-mlogloss:0.993555\n",
      "[70]\ttrain-mlogloss:0.918941\teval-mlogloss:0.992527\n",
      "[71]\ttrain-mlogloss:0.91671\teval-mlogloss:0.99118\n",
      "[72]\ttrain-mlogloss:0.914708\teval-mlogloss:0.990411\n",
      "[73]\ttrain-mlogloss:0.912564\teval-mlogloss:0.989339\n",
      "[74]\ttrain-mlogloss:0.910656\teval-mlogloss:0.988523\n",
      "[75]\ttrain-mlogloss:0.908056\teval-mlogloss:0.986817\n",
      "[76]\ttrain-mlogloss:0.905757\teval-mlogloss:0.985416\n",
      "[77]\ttrain-mlogloss:0.903611\teval-mlogloss:0.984148\n",
      "[78]\ttrain-mlogloss:0.901426\teval-mlogloss:0.982752\n",
      "[79]\ttrain-mlogloss:0.899598\teval-mlogloss:0.982142\n",
      "[80]\ttrain-mlogloss:0.897672\teval-mlogloss:0.981238\n",
      "[81]\ttrain-mlogloss:0.895522\teval-mlogloss:0.979924\n",
      "[82]\ttrain-mlogloss:0.893001\teval-mlogloss:0.9782\n",
      "[83]\ttrain-mlogloss:0.891499\teval-mlogloss:0.977583\n",
      "[84]\ttrain-mlogloss:0.889903\teval-mlogloss:0.976865\n",
      "[85]\ttrain-mlogloss:0.888095\teval-mlogloss:0.975917\n",
      "[86]\ttrain-mlogloss:0.88645\teval-mlogloss:0.975395\n",
      "[87]\ttrain-mlogloss:0.885023\teval-mlogloss:0.974796\n",
      "[88]\ttrain-mlogloss:0.883158\teval-mlogloss:0.973885\n",
      "[89]\ttrain-mlogloss:0.88113\teval-mlogloss:0.972777\n",
      "[90]\ttrain-mlogloss:0.87906\teval-mlogloss:0.971603\n",
      "[91]\ttrain-mlogloss:0.877315\teval-mlogloss:0.970849\n",
      "[92]\ttrain-mlogloss:0.875783\teval-mlogloss:0.970261\n",
      "[93]\ttrain-mlogloss:0.873862\teval-mlogloss:0.969259\n",
      "[94]\ttrain-mlogloss:0.872235\teval-mlogloss:0.968699\n",
      "[95]\ttrain-mlogloss:0.870597\teval-mlogloss:0.967788\n",
      "[96]\ttrain-mlogloss:0.869043\teval-mlogloss:0.967184\n",
      "[97]\ttrain-mlogloss:0.867274\teval-mlogloss:0.966446\n",
      "[98]\ttrain-mlogloss:0.865984\teval-mlogloss:0.966142\n",
      "[99]\ttrain-mlogloss:0.864579\teval-mlogloss:0.965554\n",
      "[100]\ttrain-mlogloss:0.862431\teval-mlogloss:0.963947\n",
      "[101]\ttrain-mlogloss:0.860749\teval-mlogloss:0.963194\n",
      "[102]\ttrain-mlogloss:0.85915\teval-mlogloss:0.962557\n",
      "[103]\ttrain-mlogloss:0.857425\teval-mlogloss:0.961756\n",
      "[104]\ttrain-mlogloss:0.856143\teval-mlogloss:0.961394\n",
      "[105]\ttrain-mlogloss:0.854695\teval-mlogloss:0.960942\n",
      "[106]\ttrain-mlogloss:0.853374\teval-mlogloss:0.960469\n",
      "[107]\ttrain-mlogloss:0.852212\teval-mlogloss:0.960003\n",
      "[108]\ttrain-mlogloss:0.850913\teval-mlogloss:0.95947\n",
      "[109]\ttrain-mlogloss:0.849127\teval-mlogloss:0.958588\n",
      "[110]\ttrain-mlogloss:0.847628\teval-mlogloss:0.957932\n",
      "[111]\ttrain-mlogloss:0.846153\teval-mlogloss:0.957248\n",
      "[112]\ttrain-mlogloss:0.844806\teval-mlogloss:0.956721\n",
      "[113]\ttrain-mlogloss:0.842939\teval-mlogloss:0.955772\n",
      "[114]\ttrain-mlogloss:0.841648\teval-mlogloss:0.95528\n",
      "[115]\ttrain-mlogloss:0.840106\teval-mlogloss:0.954691\n",
      "[116]\ttrain-mlogloss:0.838415\teval-mlogloss:0.953659\n",
      "[117]\ttrain-mlogloss:0.83713\teval-mlogloss:0.953064\n",
      "[118]\ttrain-mlogloss:0.835888\teval-mlogloss:0.95272\n",
      "[119]\ttrain-mlogloss:0.834501\teval-mlogloss:0.952188\n",
      "[120]\ttrain-mlogloss:0.833103\teval-mlogloss:0.951584\n",
      "[121]\ttrain-mlogloss:0.831711\teval-mlogloss:0.951055\n",
      "[122]\ttrain-mlogloss:0.830482\teval-mlogloss:0.950496\n",
      "[123]\ttrain-mlogloss:0.829167\teval-mlogloss:0.949854\n",
      "[124]\ttrain-mlogloss:0.828025\teval-mlogloss:0.949544\n",
      "[125]\ttrain-mlogloss:0.826797\teval-mlogloss:0.949137\n",
      "[126]\ttrain-mlogloss:0.82524\teval-mlogloss:0.948607\n",
      "[127]\ttrain-mlogloss:0.823443\teval-mlogloss:0.947535\n",
      "[128]\ttrain-mlogloss:0.821934\teval-mlogloss:0.946913\n",
      "[129]\ttrain-mlogloss:0.820796\teval-mlogloss:0.94667\n",
      "[130]\ttrain-mlogloss:0.819692\teval-mlogloss:0.946305\n",
      "[131]\ttrain-mlogloss:0.818569\teval-mlogloss:0.946128\n",
      "[132]\ttrain-mlogloss:0.817306\teval-mlogloss:0.945734\n",
      "[133]\ttrain-mlogloss:0.815893\teval-mlogloss:0.944975\n",
      "[134]\ttrain-mlogloss:0.814967\teval-mlogloss:0.944649\n",
      "[135]\ttrain-mlogloss:0.813675\teval-mlogloss:0.94407\n",
      "[136]\ttrain-mlogloss:0.812291\teval-mlogloss:0.943589\n",
      "[137]\ttrain-mlogloss:0.811089\teval-mlogloss:0.943093\n",
      "[138]\ttrain-mlogloss:0.809901\teval-mlogloss:0.942564\n",
      "[139]\ttrain-mlogloss:0.808785\teval-mlogloss:0.942176\n",
      "[140]\ttrain-mlogloss:0.807751\teval-mlogloss:0.942096\n",
      "[141]\ttrain-mlogloss:0.806342\teval-mlogloss:0.941698\n",
      "[142]\ttrain-mlogloss:0.805132\teval-mlogloss:0.941371\n",
      "[143]\ttrain-mlogloss:0.803964\teval-mlogloss:0.940897\n",
      "[144]\ttrain-mlogloss:0.802765\teval-mlogloss:0.940476\n",
      "[145]\ttrain-mlogloss:0.801659\teval-mlogloss:0.940171\n",
      "[146]\ttrain-mlogloss:0.800408\teval-mlogloss:0.939856\n",
      "[147]\ttrain-mlogloss:0.799373\teval-mlogloss:0.939566\n",
      "[148]\ttrain-mlogloss:0.798285\teval-mlogloss:0.939275\n",
      "[149]\ttrain-mlogloss:0.797237\teval-mlogloss:0.939003\n",
      "[150]\ttrain-mlogloss:0.796065\teval-mlogloss:0.93887\n",
      "[151]\ttrain-mlogloss:0.794841\teval-mlogloss:0.938487\n",
      "[152]\ttrain-mlogloss:0.793746\teval-mlogloss:0.938145\n",
      "[153]\ttrain-mlogloss:0.792567\teval-mlogloss:0.937784\n",
      "[154]\ttrain-mlogloss:0.79124\teval-mlogloss:0.937165\n",
      "[155]\ttrain-mlogloss:0.790069\teval-mlogloss:0.93688\n",
      "[156]\ttrain-mlogloss:0.789055\teval-mlogloss:0.936413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[157]\ttrain-mlogloss:0.788117\teval-mlogloss:0.936159\n",
      "[158]\ttrain-mlogloss:0.787207\teval-mlogloss:0.935956\n",
      "[159]\ttrain-mlogloss:0.786345\teval-mlogloss:0.935785\n",
      "[160]\ttrain-mlogloss:0.785283\teval-mlogloss:0.935403\n",
      "[161]\ttrain-mlogloss:0.784243\teval-mlogloss:0.935135\n",
      "[162]\ttrain-mlogloss:0.782965\teval-mlogloss:0.934605\n",
      "[163]\ttrain-mlogloss:0.781806\teval-mlogloss:0.934388\n",
      "[164]\ttrain-mlogloss:0.78089\teval-mlogloss:0.93425\n",
      "[165]\ttrain-mlogloss:0.779748\teval-mlogloss:0.933886\n",
      "[166]\ttrain-mlogloss:0.778825\teval-mlogloss:0.933733\n",
      "[167]\ttrain-mlogloss:0.77766\teval-mlogloss:0.933265\n",
      "[168]\ttrain-mlogloss:0.776652\teval-mlogloss:0.933066\n",
      "[169]\ttrain-mlogloss:0.775609\teval-mlogloss:0.932563\n",
      "[170]\ttrain-mlogloss:0.774652\teval-mlogloss:0.932405\n",
      "[171]\ttrain-mlogloss:0.773613\teval-mlogloss:0.93195\n",
      "[172]\ttrain-mlogloss:0.772634\teval-mlogloss:0.931506\n",
      "[173]\ttrain-mlogloss:0.771706\teval-mlogloss:0.931493\n",
      "[174]\ttrain-mlogloss:0.770685\teval-mlogloss:0.931085\n",
      "[175]\ttrain-mlogloss:0.769758\teval-mlogloss:0.930864\n",
      "[176]\ttrain-mlogloss:0.768741\teval-mlogloss:0.93069\n",
      "[177]\ttrain-mlogloss:0.767644\teval-mlogloss:0.93043\n",
      "[178]\ttrain-mlogloss:0.766751\teval-mlogloss:0.930257\n",
      "[179]\ttrain-mlogloss:0.765884\teval-mlogloss:0.930169\n",
      "[180]\ttrain-mlogloss:0.764953\teval-mlogloss:0.929892\n",
      "[181]\ttrain-mlogloss:0.763962\teval-mlogloss:0.929679\n",
      "[182]\ttrain-mlogloss:0.763251\teval-mlogloss:0.929605\n",
      "[183]\ttrain-mlogloss:0.762368\teval-mlogloss:0.929492\n",
      "[184]\ttrain-mlogloss:0.761637\teval-mlogloss:0.929369\n",
      "[185]\ttrain-mlogloss:0.760959\teval-mlogloss:0.929216\n",
      "[186]\ttrain-mlogloss:0.76003\teval-mlogloss:0.928981\n",
      "[187]\ttrain-mlogloss:0.75925\teval-mlogloss:0.92884\n",
      "[188]\ttrain-mlogloss:0.75845\teval-mlogloss:0.928692\n",
      "[189]\ttrain-mlogloss:0.757598\teval-mlogloss:0.92858\n",
      "[190]\ttrain-mlogloss:0.756533\teval-mlogloss:0.928231\n",
      "[191]\ttrain-mlogloss:0.755353\teval-mlogloss:0.927888\n",
      "[192]\ttrain-mlogloss:0.754436\teval-mlogloss:0.927571\n",
      "[193]\ttrain-mlogloss:0.753612\teval-mlogloss:0.927382\n",
      "[194]\ttrain-mlogloss:0.752882\teval-mlogloss:0.927231\n",
      "[195]\ttrain-mlogloss:0.752028\teval-mlogloss:0.927132\n",
      "[196]\ttrain-mlogloss:0.751013\teval-mlogloss:0.926817\n",
      "[197]\ttrain-mlogloss:0.750151\teval-mlogloss:0.926652\n",
      "[198]\ttrain-mlogloss:0.749338\teval-mlogloss:0.926713\n",
      "[199]\ttrain-mlogloss:0.74856\teval-mlogloss:0.926607\n",
      "[200]\ttrain-mlogloss:0.74755\teval-mlogloss:0.926581\n",
      "[201]\ttrain-mlogloss:0.746648\teval-mlogloss:0.926296\n",
      "[202]\ttrain-mlogloss:0.745831\teval-mlogloss:0.926262\n",
      "[203]\ttrain-mlogloss:0.745048\teval-mlogloss:0.926165\n",
      "[204]\ttrain-mlogloss:0.744195\teval-mlogloss:0.9261\n",
      "[205]\ttrain-mlogloss:0.743324\teval-mlogloss:0.925919\n",
      "[206]\ttrain-mlogloss:0.742612\teval-mlogloss:0.925877\n",
      "[207]\ttrain-mlogloss:0.741849\teval-mlogloss:0.92587\n",
      "[208]\ttrain-mlogloss:0.740974\teval-mlogloss:0.925687\n",
      "[209]\ttrain-mlogloss:0.740109\teval-mlogloss:0.925478\n",
      "[210]\ttrain-mlogloss:0.739235\teval-mlogloss:0.925321\n",
      "[211]\ttrain-mlogloss:0.738196\teval-mlogloss:0.925048\n",
      "[212]\ttrain-mlogloss:0.737353\teval-mlogloss:0.924902\n",
      "[213]\ttrain-mlogloss:0.73636\teval-mlogloss:0.924626\n",
      "[214]\ttrain-mlogloss:0.735577\teval-mlogloss:0.92454\n",
      "[215]\ttrain-mlogloss:0.734818\teval-mlogloss:0.924434\n",
      "[216]\ttrain-mlogloss:0.734016\teval-mlogloss:0.924421\n",
      "[217]\ttrain-mlogloss:0.733174\teval-mlogloss:0.924291\n",
      "[218]\ttrain-mlogloss:0.732394\teval-mlogloss:0.924173\n",
      "[219]\ttrain-mlogloss:0.731555\teval-mlogloss:0.924093\n",
      "[220]\ttrain-mlogloss:0.730943\teval-mlogloss:0.923996\n",
      "[221]\ttrain-mlogloss:0.730135\teval-mlogloss:0.924\n",
      "[222]\ttrain-mlogloss:0.729317\teval-mlogloss:0.923872\n",
      "[223]\ttrain-mlogloss:0.728495\teval-mlogloss:0.923684\n",
      "[224]\ttrain-mlogloss:0.727402\teval-mlogloss:0.923256\n",
      "[225]\ttrain-mlogloss:0.726687\teval-mlogloss:0.92323\n",
      "[226]\ttrain-mlogloss:0.726042\teval-mlogloss:0.923158\n",
      "[227]\ttrain-mlogloss:0.725434\teval-mlogloss:0.923172\n",
      "[228]\ttrain-mlogloss:0.724458\teval-mlogloss:0.922876\n",
      "[229]\ttrain-mlogloss:0.723445\teval-mlogloss:0.922662\n",
      "[230]\ttrain-mlogloss:0.722772\teval-mlogloss:0.922533\n",
      "[231]\ttrain-mlogloss:0.721986\teval-mlogloss:0.922437\n",
      "[232]\ttrain-mlogloss:0.721224\teval-mlogloss:0.922411\n",
      "[233]\ttrain-mlogloss:0.720461\teval-mlogloss:0.922355\n",
      "[234]\ttrain-mlogloss:0.719789\teval-mlogloss:0.922367\n",
      "[235]\ttrain-mlogloss:0.718986\teval-mlogloss:0.922286\n",
      "[236]\ttrain-mlogloss:0.718239\teval-mlogloss:0.922293\n",
      "[237]\ttrain-mlogloss:0.717327\teval-mlogloss:0.922183\n",
      "[238]\ttrain-mlogloss:0.716523\teval-mlogloss:0.922209\n",
      "[239]\ttrain-mlogloss:0.715735\teval-mlogloss:0.922116\n",
      "[240]\ttrain-mlogloss:0.714686\teval-mlogloss:0.921873\n",
      "[241]\ttrain-mlogloss:0.713846\teval-mlogloss:0.921622\n",
      "[242]\ttrain-mlogloss:0.712947\teval-mlogloss:0.921593\n",
      "[243]\ttrain-mlogloss:0.711993\teval-mlogloss:0.921529\n",
      "[244]\ttrain-mlogloss:0.711212\teval-mlogloss:0.921348\n",
      "[245]\ttrain-mlogloss:0.71036\teval-mlogloss:0.921348\n",
      "[246]\ttrain-mlogloss:0.709592\teval-mlogloss:0.921205\n",
      "[247]\ttrain-mlogloss:0.708807\teval-mlogloss:0.921141\n",
      "[248]\ttrain-mlogloss:0.708125\teval-mlogloss:0.921094\n",
      "[249]\ttrain-mlogloss:0.70737\teval-mlogloss:0.921121\n",
      "[250]\ttrain-mlogloss:0.706711\teval-mlogloss:0.921103\n",
      "[251]\ttrain-mlogloss:0.705934\teval-mlogloss:0.92098\n",
      "[252]\ttrain-mlogloss:0.704991\teval-mlogloss:0.920687\n",
      "[253]\ttrain-mlogloss:0.704114\teval-mlogloss:0.920412\n",
      "[254]\ttrain-mlogloss:0.703575\teval-mlogloss:0.920452\n",
      "[255]\ttrain-mlogloss:0.702895\teval-mlogloss:0.92033\n",
      "[256]\ttrain-mlogloss:0.702181\teval-mlogloss:0.920294\n",
      "[257]\ttrain-mlogloss:0.701266\teval-mlogloss:0.920098\n",
      "[258]\ttrain-mlogloss:0.700429\teval-mlogloss:0.920043\n",
      "[259]\ttrain-mlogloss:0.699738\teval-mlogloss:0.919911\n",
      "[260]\ttrain-mlogloss:0.698861\teval-mlogloss:0.919893\n",
      "[261]\ttrain-mlogloss:0.698042\teval-mlogloss:0.919715\n",
      "[262]\ttrain-mlogloss:0.697484\teval-mlogloss:0.91977\n",
      "[263]\ttrain-mlogloss:0.696697\teval-mlogloss:0.919656\n",
      "[264]\ttrain-mlogloss:0.69595\teval-mlogloss:0.919532\n",
      "[265]\ttrain-mlogloss:0.695381\teval-mlogloss:0.919586\n",
      "[266]\ttrain-mlogloss:0.694615\teval-mlogloss:0.919406\n",
      "[267]\ttrain-mlogloss:0.693813\teval-mlogloss:0.919229\n",
      "[268]\ttrain-mlogloss:0.69303\teval-mlogloss:0.919383\n",
      "[269]\ttrain-mlogloss:0.692269\teval-mlogloss:0.919367\n",
      "[270]\ttrain-mlogloss:0.691567\teval-mlogloss:0.919349\n",
      "[271]\ttrain-mlogloss:0.690812\teval-mlogloss:0.919359\n",
      "[272]\ttrain-mlogloss:0.690135\teval-mlogloss:0.919365\n",
      "[273]\ttrain-mlogloss:0.689528\teval-mlogloss:0.919424\n",
      "[274]\ttrain-mlogloss:0.688888\teval-mlogloss:0.919449\n",
      "[275]\ttrain-mlogloss:0.688089\teval-mlogloss:0.919232\n",
      "[276]\ttrain-mlogloss:0.687323\teval-mlogloss:0.919139\n",
      "[277]\ttrain-mlogloss:0.686759\teval-mlogloss:0.919243\n",
      "[278]\ttrain-mlogloss:0.686134\teval-mlogloss:0.919375\n",
      "[279]\ttrain-mlogloss:0.685379\teval-mlogloss:0.919297\n",
      "[280]\ttrain-mlogloss:0.684682\teval-mlogloss:0.919299\n",
      "[281]\ttrain-mlogloss:0.684015\teval-mlogloss:0.919294\n",
      "[282]\ttrain-mlogloss:0.683439\teval-mlogloss:0.919235\n",
      "[283]\ttrain-mlogloss:0.682654\teval-mlogloss:0.919271\n",
      "[284]\ttrain-mlogloss:0.681894\teval-mlogloss:0.919225\n",
      "[285]\ttrain-mlogloss:0.68134\teval-mlogloss:0.919332\n",
      "[286]\ttrain-mlogloss:0.680779\teval-mlogloss:0.919341\n",
      "Stopping. Best iteration:\n",
      "[276]\ttrain-mlogloss:0.687323\teval-mlogloss:0.919139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_round = 300\n",
    "param1 = {'objective': 'multi:softprob', \n",
    "          'eval_metric': 'mlogloss', \n",
    "          'num_class': 38,\n",
    "          'max_depth' : 3,\n",
    "          \"max_delta_step\": 3, \n",
    "          \"eta\": 0.25}\n",
    "\n",
    "watchlist1 = [(dtrain,'train'), (dtest, 'eval')]\n",
    "\n",
    "bst = xgb.train(param1, dtrain, num_round, watchlist1, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmtest = xgb.DMatrix(test_array) \n",
    "pred_prob_xgb = bst.predict(dmtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba_df = pd.DataFrame(pred_prob_xgb, columns=rf.classes_)\n",
    "proba_df.columns = proba_df.columns.map(lambda x: \"TripType_\" + str(x))\n",
    "sub_df = pd.concat([test[[\"VisitNumber\"]], proba_df], axis=1)\n",
    "sub_df.to_csv(\"../submission_0409_noProb_xgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
